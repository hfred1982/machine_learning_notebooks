{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Découverte des autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après des tentatives de système de recommendation de film en se basant sur des regressions, on va tenter une nouvelle approche en utilisant les autoencoders qui sont, semble-t-il, particulièrement adaptés à ce genre de problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données\n",
    "\n",
    "Les notes ont été parsées depuis un site de notation, mais ca n'est pas le sujet ici. Les données sont stockées dans un fichier dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "outfile = open('results.dmp', 'rb')\n",
    "datas = pickle.load(outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a fait au plus simple, datas est un dictionnaire donc les clés sont les ids des films et les valeurs sont des dictionnaires contenant les infos du film (titre, année, acteurs, ... et les différentes notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 368836,\n",
       " 'title': 'Brisby et le Secret de NIMH',\n",
       " 'year': '1982',\n",
       " 'note_globale': 7.6,\n",
       " 'url': 'https://www.senscritique.com/film/Brisby_et_le_Secret_de_NIMH/368836',\n",
       " 'image': 'https://media.senscritique.com/media/000016246779/90/Brisby_et_le_Secret_de_NIMH.jpg',\n",
       " 'duration': '1 h 22 min',\n",
       " 'release_date': '16 juillet 1982',\n",
       " 'genres': 'Animation,drame,fantastique,science-fiction',\n",
       " 'categorie': \"Long-métrage d'animation\",\n",
       " 'directors': 'Don Bluth',\n",
       " 'actors': 'Derek Jacobi,Elizabeth Hartman,Arthur Malet',\n",
       " 'note_A': None,\n",
       " 'note_B': 8.0,\n",
       " 'note_C': 8.0,\n",
       " ...\n",
       " 'note_ZZZZ': 8.0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[368836]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque film, on a donc une liste de notes (les clés préfixées par note). On va devoir réorganiser ces données pour les fournir en entrée de notre autoencoder. L'idée est de créer tableau numpy avec les colonnes correspondant au film, chaque ligne correspondant à un utilisateur.\n",
    "\n",
    "## Préparation des données\n",
    "\n",
    "On définit une fonction qui parcourt les données et créé le tableau correspondant.\n",
    "NB : je n'utilise pas de dataframe pandas comme habituellement car les performances sont catastrophiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def formatData(data):\n",
    "    \"\"\"Transform the dictionnary data into numpy array for machine learning\n",
    "    \n",
    "    \"\"\"\n",
    "    users = []\n",
    "    for item in data.values():\n",
    "        for note in item.keys():\n",
    "            if \"note_\" in note and note != 'note_globale' and item[note] is not None:\n",
    "                user = note.replace('note_','')\n",
    "                if user not in users:\n",
    "                    users.append(user)\n",
    "                \n",
    "    films = list(data.keys())\n",
    "\n",
    "    nb_movies = len(films)\n",
    "    nb_users = len(users)\n",
    "\n",
    "\n",
    "    films_id_to_num = {}\n",
    "    users_name_to_num = {}\n",
    "\n",
    "    for i in range(0,len(films)):\n",
    "        films_id_to_num[films[i]] = i\n",
    "\n",
    "    for i in range(0,len(users)):\n",
    "        users_name_to_num[users[i]] = i\n",
    "\n",
    "    X = np.zeros([nb_users, nb_movies])\n",
    "\n",
    "\n",
    "    for item in data.values():\n",
    "        for note in item.keys():\n",
    "            if \"note_\" in note and note != 'note_globale' and item[note] is not None:\n",
    "                num_line = users_name_to_num[note.replace('note_','')]\n",
    "                num_col = films_id_to_num[item['id']]\n",
    "                X[num_line,num_col] = item[note]\n",
    "    \n",
    "    return X, films, users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, films, users = formatData(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc notre tableau X et les 2 tableaux permettant de faire respectivement le lien entre l'id du film et la colonne correspondante et le nom du user et la ligne correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 86466)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86466 films... c'est beaucoup. Voir même ridicule. On a récupéré des données qui n'ont pas vraiment de sens, le film qui n'est noté que par un ou deux utilisateur n'a pas vraiment vocation à être analysé. On écrit donc une fonction pour faire le ménage et ne garder que les films qui ont au moins 250 notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(X, films, min_num_notes = 150):\n",
    "    \n",
    "    # Count number of film to keep (for performance better than rebuild the array)\n",
    "    nb_users = len(X[:,0])\n",
    "    nb_movies = len(X[0,:])\n",
    "    \n",
    "    nb_movies_to_keep = 0\n",
    "    for i in range(nb_movies):\n",
    "        if np.size(np.nonzero(X[:,i])) > min_num_notes:\n",
    "            nb_movies_to_keep += 1\n",
    "\n",
    "    X_filtered = np.zeros([nb_users, nb_movies_to_keep])\n",
    "    \n",
    "    \n",
    "    # Filling the array with data\n",
    "    films_to_keep = []\n",
    "    current=0\n",
    "\n",
    "    for i in range(nb_movies):\n",
    "        if np.size(np.nonzero(X[:,i])) > min_num_notes:\n",
    "            X_filtered[:,current] = X[:,i]\n",
    "            current += 1\n",
    "            films_to_keep.append(films[i])\n",
    "    \n",
    "    X = X_filtered\n",
    "    films = films_to_keep\n",
    "    \n",
    "    return X, films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, films =  cleanData(X, films, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 1199)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1200 films, c'est plus raisonnable et suffisant pour un premier test. Il faudrait peut-être également supprimer les utilisateurs qui n'ont pas noté suffisamment de films (à réfléchir si cela a un sens).\n",
    "\n",
    "Notre tableau est prêt. Il nous reste à construire les dictionnaires pour retrouver les films/utilisateurs en fonction des colonnes/lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildReverseList(liste):\n",
    "    new_liste = {}\n",
    "    for i in range(len(liste)):\n",
    "        new_liste[liste[i]] = i\n",
    "    return new_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_id_to_num = buildReverseList(films)\n",
    "users_name_to_num = buildReverseList(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_movies = len(films)\n",
    "nb_users = len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de l'autoencoder\n",
    "\n",
    "On va réutiliser un morceau de code qu'on retrouve un peu partout et qui utilise pytorch pour créer rapidement un autoencoder. La difficulté ici tient au fait qu'il ne faut pas rétropropager l'erreur lorsque le film n'a pas été vu par l'utilisateur sinon, on pourrait tout simplement utiliser les librairies standard sans rien écrire nous même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Creating the architecture of the Neural Network\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sae est donc notre instance d'autoencoder. Rien de particulier jusque là. On utilise les bibliothèque sklearn pour créer le training set et le test set (à voir si c'est aussi simple avec pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(X_train)\n",
    "test_set = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine notre réseau. C'est ici la grosse difficulté parce qu'il faut customiser le calcul de l'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 1.742316641815268\n",
      "epoch: 2 loss: 1.5375415669353552\n",
      "epoch: 3 loss: 1.5369872627804497\n",
      "epoch: 4 loss: 1.5365561653105855\n",
      "epoch: 5 loss: 1.5367702856344025\n",
      "epoch: 6 loss: 1.5340909672523577\n",
      "epoch: 7 loss: 1.5349719458431026\n",
      "epoch: 8 loss: 1.5349076357637743\n",
      "epoch: 9 loss: 1.534917788142103\n",
      "epoch: 10 loss: 1.5323347102974552\n",
      "epoch: 11 loss: 1.5329856863953406\n",
      "epoch: 12 loss: 1.530052840408911\n",
      "epoch: 13 loss: 1.5336292175430775\n",
      "epoch: 14 loss: 1.53366980642044\n",
      "epoch: 15 loss: 1.5328542101868838\n",
      "epoch: 16 loss: 1.5323147280520493\n",
      "epoch: 17 loss: 1.53183271296583\n",
      "epoch: 18 loss: 1.5314819879819732\n",
      "epoch: 19 loss: 1.531166345888099\n",
      "epoch: 20 loss: 1.5310304305879014\n",
      "epoch: 21 loss: 1.5309771268368306\n",
      "epoch: 22 loss: 1.5308580780685241\n",
      "epoch: 23 loss: 1.5309373718648702\n",
      "epoch: 24 loss: 1.5316064557515274\n",
      "epoch: 25 loss: 1.5298965763314283\n",
      "epoch: 26 loss: 1.5303870712737182\n",
      "epoch: 27 loss: 1.531016652644922\n",
      "epoch: 28 loss: 1.5310395633049427\n",
      "epoch: 29 loss: 1.5310833946182556\n",
      "epoch: 30 loss: 1.5311583865733953\n",
      "epoch: 31 loss: 1.5311297896719156\n",
      "epoch: 32 loss: 1.5311196328297014\n",
      "epoch: 33 loss: 1.5311163993306987\n",
      "epoch: 34 loss: 1.5311267013448793\n",
      "epoch: 35 loss: 1.5310883169853602\n",
      "epoch: 36 loss: 1.5308535464481718\n",
      "epoch: 37 loss: 1.53114030416833\n",
      "epoch: 38 loss: 1.5298761261035316\n",
      "epoch: 39 loss: 1.5304454970858892\n",
      "epoch: 40 loss: 1.5306358172031747\n",
      "epoch: 41 loss: 1.5309351068388903\n",
      "epoch: 42 loss: 1.5303328346136973\n",
      "epoch: 43 loss: 1.5303705225465238\n",
      "epoch: 44 loss: 1.5293343051305697\n",
      "epoch: 45 loss: 1.525417412857632\n",
      "epoch: 46 loss: 1.5261911329769546\n",
      "epoch: 47 loss: 1.5270780114183886\n",
      "epoch: 48 loss: 1.5284946453032524\n",
      "epoch: 49 loss: 1.5270968881042837\n",
      "epoch: 50 loss: 1.528624976971778\n"
     ]
    }
   ],
   "source": [
    "# Training the SAE\n",
    "nb_users = X_train[:,0].size\n",
    "nb_epoch = 50\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On laisse tous les paramètres par défaut... c'est juste un premier jet pour découvrir les autoencoders et on teste le résultat sur notre test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.5139577117563043\n"
     ]
    }
   ],
   "source": [
    "# Testing the SAE\n",
    "nb_users = X_test[:,0].size\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(test_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user])\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK l'erreur est sensiblement la même que sur le training set, ca parait bon (voir même trop bon... à réfléchir).\n",
    "\n",
    "## Utilisation de l'autoencoder\n",
    "\n",
    "Essayons maintenant de faire des recommendations (pour moi tant qu'à faire). Pour cela, il faut mettre en entrée de notre réseau l'ensemble des notes de l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the SAE\n",
    "all_set = torch.FloatTensor(X)\n",
    "input = Variable(all_set[users_name_to_num['hfred1982']]).unsqueeze(0)\n",
    "output = sae(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable output contient donc les notes prédites par notre réseau pour les n films étudiés. Première question : est-ce qu'on fait mieux qu'un estimateur simpliste qui prendrait simplement la note du public comme prédiction ? Le note du public étant disponible dans nos données, c'est facile à vérifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de l'autoencoder : 1.3939345311016689\n",
      "Erreur de la note globale : 1.4317210178265514\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "error_note_globale = 0\n",
    "nb_films = 0\n",
    "for i in range(nb_movies):\n",
    "    if X[users_name_to_num['hfred1982']][i] != 0:\n",
    "        error += (X[users_name_to_num['hfred1982']][i] - output.data[0][i])**2\n",
    "        error_note_globale += (X[users_name_to_num['hfred1982']][i] - datas[films[i]]['note_globale'])**2\n",
    "        nb_films +=1 \n",
    "        \n",
    "print(\"Erreur de l'autoencoder : \"+str(np.sqrt(error/nb_films)))\n",
    "print(\"Erreur de la note globale : \"+str(np.sqrt(error_note_globale/nb_films)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait mieux ouf ... Allons-y alors et faisons notre première recommendation de film. Auparavant, on va nettoyer notre sortie, en mettant 0 aux films déjà vus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in range(0,nb_movies):\n",
    "    if X[users_name_to_num['hfred1982']][i] == 0:\n",
    "        prediction.append(output.data[0][i])\n",
    "    else:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et le meilleur film prédit est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"L'Aurore\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meilleur film prédit\n",
    "datas[films[np.argmax(np.array(prediction))]]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca semble crédible même si a priori je ne vois pas pourquoi ce film me serait proposé plutôt qu'un autre. Une question à vérifier tout de même : est-ce que ca n'est pas tout simplement le film qui a la meilleure moyenne parmi les notes récupérées ? Auquel cas, l'autoencoder ne sert pas à grand chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chantons sous la pluie'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On calcule la moyenne de chaque film sur le test set (on met 0 si on l'a déjà vu)\n",
    "moy_films = []\n",
    "for i in range(nb_movies):\n",
    "    if X[users_name_to_num['hfred1982']][i] == 0:\n",
    "        moy_films.append(sum(X_test[:,i])/np.count_nonzero(X_test[:,i]))\n",
    "    else:\n",
    "        moy_films.append(0)\n",
    "\n",
    "# On regarde quel film a la meilleure moyenne\n",
    "datas[films[np.argmax(moy_films)]]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvé ! On ne me propose pas bêtement le film avec la meilleure moyenne, c'est donc un conseil \"personalisé\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons maintenant de voir un peu plus en détail comment fonctionne l'autoencoder : d'une certaine façon, l'autoencoder va détecter automatiquement certaines features des films qui vont permettre d'expliquer leur note. Pour voir cela, on peut essayer de regarder le premier layer et de voir quels sont les poids associés à chaque film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 1.0979e-01 -1.3440e-02 -9.0807e-02  ...  -8.7257e-05  1.5656e-02  1.2193e-02\n",
       "-2.0495e-02  7.6809e-02  3.7586e-02  ...   3.9110e-02  5.9315e-02  5.8146e-02\n",
       "-1.2941e-01 -3.6356e-01 -1.1999e-01  ...   7.4995e-02 -6.1159e-02  9.4228e-02\n",
       "                ...                   ⋱                   ...                \n",
       "-1.5531e-02 -2.6397e-01 -1.5148e-02  ...   6.3949e-02  5.2527e-02  6.5169e-02\n",
       "-3.2325e-01 -1.8299e-01 -4.0070e-01  ...   6.1947e-01  6.3777e-01  6.3676e-01\n",
       "-1.4615e-02 -4.8421e-02 -6.2948e-02  ...   8.2534e-03 -9.4053e-03  2.8250e-03\n",
       "[torch.FloatTensor of size 20x1199]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.fc1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids sont stockés dans un tenseur 20x(nb_films). On peut donc facilement pour chaque noeud regarder quels sont les films qui ont le poid le plus fort associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 films au poids le plus important sur le noeud 1 :\n",
      "\tRox et Rouky\n",
      "\tUn long dimanche de fiançailles\n",
      "\tStar Wars : Les Derniers Jedi\n",
      "\tAladdin\n",
      "\tLa Petite Sirène\n",
      "\tStar Wars : Épisode III - La Revanche des Sith\n",
      "\tLa Liste de Schindler\n",
      "\tStar Wars : Le Réveil de la Force\n",
      "\tLe Roi Lion\n",
      "\tLa Belle et la Bête\n"
     ]
    }
   ],
   "source": [
    "print(\"Les 10 films au poids le plus important sur le noeud 1 :\")\n",
    "for i in sae.fc1.weight[1].sort()[1][-10:].data:\n",
    "    print(\"\\t\"+datas[films[i]]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficile de voir un critère qui serait valable pour tous ces films. Néanmoins, on peut remarquer la présence de 5 dessins animés et de 3 Stars Wars. C'est intéressant car on peut difficilement croire que c'est le hasard qui a regroupé ces films alors que l'autoencoder lui n'a aucun moyen de savoir que ces films appartiennent à la même franchise. On peut donc penser qu'il a donc bien \"détecté\" une feature qui est commune à tous (même si encore une fois, elle est difficile à expliciter). Regardons sur un autre noeud pour confirmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 films au poids le plus important sur le noeud 2 :\n",
      "\t10 Cloverfield Lane\n",
      "\tPacific Rim\n",
      "\tTaken\n",
      "\tInception\n",
      "\tSpider-Man : New Generation\n",
      "\tCoco\n",
      "\tCaptain America : Civil War\n",
      "\tDoctor Strange\n",
      "\tAvengers : Endgame\n",
      "\tLa Forme de l'eau\n"
     ]
    }
   ],
   "source": [
    "print(\"Les 10 films au poids le plus important sur le noeud 2 :\")\n",
    "for i in sae.fc1.weight[2].sort()[1][-10:].data:\n",
    "    print(\"\\t\"+datas[films[i]]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, pas de thème véritablement unificateur, mais tout de même 4 films Marvels regroupés. C'est bon signe.\n",
    "On va sauvegarder notre modèle pour repartir sur la même analyse la prochaine fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sae.state_dict(), 'sae.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà pour un premier jet, reste bien entendu à tuner les hyperparamètres et voir si on peut en tirer plus d'enseignement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
